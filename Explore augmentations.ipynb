{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Explore data augmentations\n",
    "\n",
    "This notebook will be used to test different data augmentation strategies. In your config file, you can modify the augmentations by adding `data_augmentation_options`. For example, I would like to add a random RGB to gray transform with a probability of 0.2:\n",
    "```\n",
    "data_augmentation_options {\n",
    "    random_rgb_to_gray {\n",
    "    probability: 0.2\n",
    "    }\n",
    "```\n",
    "\n",
    "A complete list of augmentation is provided the [`preprocessor.proto` file of the Tf Object Detection API](https://github.com/tensorflow/models/blob/master/research/object_detection/protos/preprocessor.proto)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from matplotlib.patches import Rectangle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recenter_image(image):\n",
    "    # ssd preprocessing\n",
    "    image += [123.68, 116.779, 103.939]\n",
    "    return image\n",
    "\n",
    "def display_instances(image, bboxes, classes):\n",
    "    image = recenter_image(image)\n",
    "    w, h, _ = image.shape\n",
    "    # resize the bboxes\n",
    "    bboxes[:, [0, 2]] *= w\n",
    "    bboxes[:, [1, 3]] *= h\n",
    "    \n",
    "    f, ax = plt.subplots(1, figsize=(10, 10))\n",
    "    ax.imshow(image.astype(np.uint8))\n",
    "    for bb, cl in zip(bboxes, classes):\n",
    "        y1, x1, y2, x2 = bb\n",
    "        rec = Rectangle((x1, y1), x2-x1, y2-y1, facecolor='none', edgecolor='r', linewidth=2)\n",
    "        ax.add_patch(rec)\n",
    "    plt.show()\n",
    "\n",
    "def display_batch(batch):\n",
    "    # get images, bboxes and classes\n",
    "    batched_images = batch[0]['image'].numpy()\n",
    "    batched_bboxes = batch[1]['groundtruth_boxes'].numpy()\n",
    "    batched_classes = batch[1]['groundtruth_classes'].numpy()\n",
    "    num_bboxes = batch[1]['num_groundtruth_boxes'].numpy()\n",
    "    batch_size = batched_images.shape[0]\n",
    "    for idx in range(batch_size):\n",
    "        display_instances(batched_images[idx, ...], \n",
    "                          batched_bboxes[idx, :num_bboxes[idx], :],\n",
    "                          batched_classes[idx, ...])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Display augmentations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'tensorflow'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_16020/464809798.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mutils\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mget_train_input\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mc:\\Users\\aliwa\\Desktop\\P1-vision-starter-main\\utils.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mlogging\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcompat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mv1\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mobject_detection\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minputs\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mtrain_input\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mobject_detection\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprotos\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0minput_reader_pb2\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'tensorflow'"
     ]
    }
   ],
   "source": [
    "from utils import get_train_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = get_train_input(\"../solution/pipeline_new.config\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "for batch in train_dataset.take(1):\n",
    "    display_batch(batch)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
